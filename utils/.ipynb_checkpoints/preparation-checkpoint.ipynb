{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_missing_values(df):\n",
    "    \"\"\"\n",
    "    Filter rows with missing value\n",
    "    \"\"\"\n",
    "    import pandas\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    m = pd.Series(False, index=df.index) # Boolean indexing\n",
    "    m |= ( # ...to filter specific values\n",
    "    (df.node_caps == '?') &\n",
    "    (df.breast_quad == '?') &\n",
    "    (df.irradiat == 'NaN'))\n",
    "    df = df[~m]\n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_df(input_df):\n",
    "    \"\"\"\n",
    "    Label encoding; categorical (str) variable to int\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    lb = LabelEncoder() # use lb.inverse_transform(encoded_array) to decode\n",
    "    \n",
    "    # Encode categorical data to int values\n",
    "    df_encoded = (df\n",
    "                  .astype(str) # converts all values to str\n",
    "                  .apply(lb.fit_transform)) # encodes all values to int\n",
    "    \n",
    "    return df_encoded, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_XOR_example(attr_dict_sample):\n",
    "    \"\"\"\n",
    "    attr_dict_sample; \n",
    "    dict containing attributes and attributes value range for sample dataset\n",
    "    {arg_1 : [values], ...}\n",
    "    \n",
    "    returns a sample record labelled as per the XOR function (or parity function)\n",
    "    depending on the number of attributes in attr_dict_sample\n",
    "    \"\"\"\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    attributes = attr_dict_sample.keys()\n",
    "    record = {k : None for k in attributes}\n",
    "    record['Class'] = random.choice([0, 1])\n",
    "    \n",
    "    if record['Class'] == 1:        \n",
    "        attr_pos_count = random.choice( [n for n in range(len(attributes)+1) if n%2==0] )\n",
    "    else:\n",
    "        attr_pos_count = random.choice( [n for n in range(len(attributes)+1) if n%2==1] )\n",
    "    attr_pos = random.sample(attributes, attr_pos_count)\n",
    "    \n",
    "    for a in attributes:\n",
    "        if a in attr_pos:\n",
    "            record[a] = 1\n",
    "        else:\n",
    "            possible_values = [v for v in attr_dict_sample[a] if v != 1]\n",
    "            record[a] = random.choice(possible_values)\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "def generate_XOR_dataset(n_examples,\n",
    "                         attr_dict,\n",
    "                         n_attributes,\n",
    "                         no_duplicate=True):\n",
    "    \"\"\"\n",
    "    Generates a list of examples labelled as per the XOR function,\n",
    "    using attributes defined in attr_dict \n",
    "    \"\"\"\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    attributes = list(attr_dict.keys())\n",
    "    attributes = [a for a in attributes if a != 'Class']\n",
    "\n",
    "    attributes_sample = random.sample(attributes, \n",
    "                                      min(n_attributes, len(attributes)))\n",
    "    attr_dict_sample = {\n",
    "        k : v\n",
    "        for k, v in attr_dict.items()\n",
    "        if k in attributes_sample\n",
    "    }\n",
    "    \n",
    "    dataset = []\n",
    "    if no_duplicate :\n",
    "        example_space_size = np.prod([len(v) for v in attr_dict_sample.values()])       \n",
    "        n_examples = min(n_examples, example_space_size)\n",
    "        \n",
    "        print(\"Space size:\", example_space_size)\n",
    "        \n",
    "    while(len(dataset) < n_examples):\n",
    "        new_example = generate_XOR_example(attr_dict_sample)\n",
    "        if not no_duplicate or new_example not in dataset:\n",
    "            dataset.append(new_example)\n",
    "    \n",
    "    dataset_df = pd.DataFrame(dataset)\n",
    "    print(\"Dataset size:\", len(dataset))\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
