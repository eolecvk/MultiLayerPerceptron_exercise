{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization of XOR: parity function problem\n",
    "\n",
    "Generalize the previous analysis with functions taking 3 to 10 input variables.  \n",
    "We shall use a dataset to train on the parity function problem:\n",
    "fonction returns 1 when there is an even number of 1-valued attributes; else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run utils/helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run utils/preparation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run utils/exploration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run utils/MLP_utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "\n",
    "We first load the attribute dictionary for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age [2, 3, 4, 1, 5, 0]\n",
      "menopause [2, 0, 1]\n",
      "tumor_size [2, 6, 5, 4, 7, 1, 0, 3, 8, 10, 9]\n",
      "inv_nodes [0, 4, 2, 5, 6, 3, 1]\n",
      "node_caps [2, 1, 0]\n",
      "deg_malig [2, 0, 1]\n",
      "breast [1, 0]\n",
      "breast_quad [3, 1, 2, 5, 4, 0]\n",
      "irradiat [0, 1]\n",
      "Class [1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Load encoded attribute values from the Breast Cancer dataset\n",
    "fpath = \"/tmp/DM2_attr_val_encoded.json\"\n",
    "attr_val_breast_dataset_encoded = load_json(fpath)\n",
    "    \n",
    "# Preview\n",
    "for k, v in attr_val_breast_dataset_encoded.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then generate sample records randomly and classify them using the parity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_XOR_dataset(n_examples=1000,\n",
    "                         attr_dict=attr_val_breast_dataset_encoded,\n",
    "                         n_attributes=8,\n",
    "                         no_duplicate=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>age</th>\n",
       "      <th>breast</th>\n",
       "      <th>breast_quad</th>\n",
       "      <th>deg_malig</th>\n",
       "      <th>inv_nodes</th>\n",
       "      <th>irradiat</th>\n",
       "      <th>menopause</th>\n",
       "      <th>node_caps</th>\n",
       "      <th>tumor_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  age  breast  breast_quad  deg_malig  inv_nodes  irradiat  menopause  \\\n",
       "0      1    4       1            2          1          0         1          1   \n",
       "1      0    3       1            2          0          0         1          1   \n",
       "2      0    2       0            4          0          3         0          2   \n",
       "3      0    4       0            0          0          4         1          2   \n",
       "4      0    5       0            1          1          4         0          1   \n",
       "\n",
       "   node_caps  tumor_size  \n",
       "0          2          10  \n",
       "1          0           5  \n",
       "2          0           1  \n",
       "3          2           7  \n",
       "4          2           6  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_parity_fct = generate_dataset(generate_record, 1000)\n",
    "dataset_parity_fct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MLP on the Parity function dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample records:\n",
      "(4, 1, 2, 1, 0, 1, 1, 2, 10)\n",
      "(3, 1, 2, 0, 0, 1, 1, 0, 5)\n",
      "(2, 0, 4, 0, 3, 0, 2, 0, 1)\n",
      "(4, 0, 0, 0, 4, 1, 2, 2, 7)\n",
      "(5, 0, 1, 1, 4, 0, 1, 2, 6)\n",
      "(0, 1, 1, 2, 6, 1, 1, 0, 8)\n",
      "(1, 1, 3, 0, 4, 1, 2, 1, 4)\n",
      "(5, 1, 3, 1, 5, 0, 2, 2, 10)\n",
      "(5, 0, 2, 2, 2, 1, 1, 2, 4)\n",
      "(0, 0, 1, 1, 3, 0, 1, 2, 8)\n",
      "\n",
      "Sample labels\n",
      "[1, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Input data, labels\n",
    "X, y = get_nn_inputs(dataset_parity_fct)\n",
    "\n",
    "# Preview\n",
    "print(\"Sample records:\")\n",
    "for r in X[:10]:\n",
    "    print(r)\n",
    "print(\"\\nSample labels\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes' : (list(range(max_layer)), list(range(max_neurons))), # (100,)\n",
    "    'activation' : ['identity', 'logistic', 'tanh', 'relu'], # 'relu'\n",
    "    'solver' : ['lbfgs', 'sgd', 'adam'], #'adam'\n",
    "    'alpha' : np.linspace(start=0.00001, stop=0.001, num=50), #0.0001\n",
    "    'learning_rate' : ['constant', 'invscaling', 'adaptive'], #'constant'\n",
    "    'learning_rate_init' : np.linspace(start=0.0001, stop=0.01, num=50), #0.001\n",
    "    'momentum' : np.linspace(start=0.1, stop=1, num=10) #0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-65009cb50cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m param_grid = {\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;34m'hidden_layer_sizes'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_space_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;34m'activation'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 'relu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m'solver'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#'adam'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import random \n",
    "\n",
    "\n",
    "# def layer_space_sample(n, max_layer=2, max_neurons=2):\n",
    "#     from itertools import product\n",
    "#     from random import shuffle\n",
    "\n",
    "#     neuron_values = list(range(max_neurons))\n",
    "#     shuffle(neuron_values)\n",
    "    \n",
    "#     layer_space = product(neuron_values, repeat=max_layer)\n",
    "#     layer_space_sample = []\n",
    "#     while n > 0:\n",
    "#         try:\n",
    "#             layer_space_sample.append(next(layer_space))\n",
    "#             n -= 1\n",
    "#         except StopIteration as e:\n",
    "#             print(\" n > space_size\")\n",
    "#             break\n",
    "#     return layer_space_sample\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes' : layer_space_sample(10000), # (100,)\n",
    "#     'activation' : ['identity', 'logistic', 'tanh', 'relu'], # 'relu'\n",
    "#     'solver' : ['lbfgs', 'sgd', 'adam'], #'adam'\n",
    "#     'alpha' : np.linspace(start=0.00001, stop=0.001, num=50), #0.0001\n",
    "#     'learning_rate' : ['constant', 'invscaling', 'adaptive'], #'constant'\n",
    "#     'learning_rate_init' : np.linspace(start=0.0001, stop=0.01, num=50), #0.001\n",
    "#     'momentum' : np.linspace(start=0.1, stop=1, num=10) #0.9\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...lib/python3/dist-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7fa5ffc9f1e0, file \"/...on3/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/lib/python3/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/lib/python3/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...lib/python3/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/lib/python3/dist-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...lib/python3/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fa5ffc9f1e0, file \"/...on3/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/lib/python3/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/lib/python3/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...lib/python3/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/lib/python3/dist-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/lib/python3/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/lib/python3/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/lib/python3/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/usr/lib/python3/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/lib/python3/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 15, 16, 43, 40, 754275, tzinfo=tzutc()), 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'session': '67FAEBD4E8A94C628B76709A783A108B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'67FAEBD4E8A94C628B76709A783A108B']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 15, 16, 43, 40, 754275, tzinfo=tzutc()), 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'session': '67FAEBD4E8A94C628B76709A783A108B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'67FAEBD4E8A94C628B76709A783A108B'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 15, 16, 43, 40, 754275, tzinfo=tzutc()), 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'session': '67FAEBD4E8A94C628B76709A783A108B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-54-ea3459cd092d>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fa5c0398470, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fa5a1eff5d0, file \"<ipython-input-54-ea3459cd092d>\", line 16>\n        result = <ExecutionResult object at 7fa5c0398470, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fa5a1eff5d0, file \"<ipython-input-54-ea3459cd092d>\", line 16>, result=<ExecutionResult object at 7fa5c0398470, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fa5a1eff5d0, file \"<ipython-input-54-ea3459cd092d>\", line 16>\n        self.user_global_ns = {'In': ['', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', \"get_ipython().magic('run utils/preparation.ipynb')\", \"get_ipython().magic('run utils/exploration.ipynb')\", \"get_ipython().magic('run utils/MLP_utils.ipynb')\", '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', 'errno.ENOENT', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', 'def parity_fct(attr_values):\\n    return (attr_va...pend(new_record)\\n    return pd.DataFrame(records)', 'dataset_parity_fct = generate_dataset(generate_record, 1000)\\ndataset_parity_fct.head()', '# Input data, labels\\nX, y = get_nn_inputs(dataset_parity_fct)\\n\\nprint(X[:10])\\nprint()\\nprint(y[:10])', '# Input data, labels\\nX, y = get_nn_inputs(datase...  print(r)\\nprint(\"\\\\nSample labels\")\\nprint(y[:10])', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'layer_sizes_space = [ tuple([i]) for i in range(..._rate\" : [\\'constant\\', \\'invscaling\\', \\'adaptive\\']\\n}', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'layer_sizes_space = [ tuple([i]) for i in range(..._rate\" : [\\'constant\\', \\'invscaling\\', \\'adaptive\\']\\n}', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', ...], 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {12:    Class  age  breast  breast_quad  deg_malig  i...       2           7  \n4          2           6  , 20: {'hidden_layer_sizes': [(2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), ...], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, 23: <generator object random_layer_size>, 24: <generator object random_layer_size>, 42: {'hidden_layer_sizes': [(9,)], 'learning_rate': ['constant', 'invscaling', 'adaptive']}}, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'X': [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], '_': {'hidden_layer_sizes': [(9,)], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, '_12':    Class  age  breast  breast_quad  deg_malig  i...       2           7  \n4          2           6  , '_20': {'hidden_layer_sizes': [(2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), ...], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, '_23': <generator object random_layer_size>, '_24': <generator object random_layer_size>, ...}\n        self.user_ns = {'In': ['', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', \"get_ipython().magic('run utils/preparation.ipynb')\", \"get_ipython().magic('run utils/exploration.ipynb')\", \"get_ipython().magic('run utils/MLP_utils.ipynb')\", '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', 'errno.ENOENT', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', 'def parity_fct(attr_values):\\n    return (attr_va...pend(new_record)\\n    return pd.DataFrame(records)', 'dataset_parity_fct = generate_dataset(generate_record, 1000)\\ndataset_parity_fct.head()', '# Input data, labels\\nX, y = get_nn_inputs(dataset_parity_fct)\\n\\nprint(X[:10])\\nprint()\\nprint(y[:10])', '# Input data, labels\\nX, y = get_nn_inputs(datase...  print(r)\\nprint(\"\\\\nSample labels\")\\nprint(y[:10])', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'layer_sizes_space = [ tuple([i]) for i in range(..._rate\" : [\\'constant\\', \\'invscaling\\', \\'adaptive\\']\\n}', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'layer_sizes_space = [ tuple([i]) for i in range(..._rate\" : [\\'constant\\', \\'invscaling\\', \\'adaptive\\']\\n}', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', ...], 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {12:    Class  age  breast  breast_quad  deg_malig  i...       2           7  \n4          2           6  , 20: {'hidden_layer_sizes': [(2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), ...], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, 23: <generator object random_layer_size>, 24: <generator object random_layer_size>, 42: {'hidden_layer_sizes': [(9,)], 'learning_rate': ['constant', 'invscaling', 'adaptive']}}, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'X': [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], '_': {'hidden_layer_sizes': [(9,)], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, '_12':    Class  age  breast  breast_quad  deg_malig  i...       2           7  \n4          2           6  , '_20': {'hidden_layer_sizes': [(2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), ...], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, '_23': <generator object random_layer_size>, '_24': <generator object random_layer_size>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/eolus/Desktop/DAUPHINE/data_mining/DM/DM2/MultiLayerPerceptron_exercise/<ipython-input-54-ea3459cd092d> in <module>()\n     11     cv=10, # 10-fold cross-validation\n     12     verbose=0,\n     13     random_state=None\n     14 )\n     15 \n---> 16 random_search.fit(X, y)\n     17 print(\"best params:\\n{}\".format(random_search.best_params_))\n     18 print(\"best score :\\n{}\".format(random_search.best_score_))\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=10, error_score='raise',\n ...turn_train_score='warn', scoring=None, verbose=0), X=[(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], y=[1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>\n        X = [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...]\n        y = [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Nov 15 17:43:54 2017\nPID: 3244                                    Python 3.6.3: /usr/bin/python3\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], {'score': <function _passthrough_scorer>}, array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), 0, {'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], {'score': <function _passthrough_scorer>}, array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), 0, {'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], y=[1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], scorer={'score': <function _passthrough_scorer>}, train=array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), verbose=0, parameters={'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1, verbose=False,\n       warm_start=False)>\n        X_train = [(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...]\n        y_train = [0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...]\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...], y=[0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...])\n    968         Returns\n    969         -------\n    970         self : returns a trained MLP model.\n    971         \"\"\"\n    972         return self._fit(X, y, incremental=(self.warm_start and\n--> 973                                             hasattr(self, \"classes_\")))\n        self = MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False)\n    974 \n    975     @property\n    976     def partial_fit(self):\n    977         \"\"\"Fit the model to data matrix X and target y.\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...], y=[0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...], incremental=False)\n    321         if not hasattr(hidden_layer_sizes, \"__iter__\"):\n    322             hidden_layer_sizes = [hidden_layer_sizes]\n    323         hidden_layer_sizes = list(hidden_layer_sizes)\n    324 \n    325         # Validate input parameters.\n--> 326         self._validate_hyperparameters()\n        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1, verbose=False,\n       warm_start=False)>\n    327         if np.any(np.array(hidden_layer_sizes) <= 0):\n    328             raise ValueError(\"hidden_layer_sizes must be > 0, got %s.\" %\n    329                              hidden_layer_sizes)\n    330 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False))\n    419         # raise ValueError if not registered\n    420         supported_activations = ('identity', 'logistic', 'tanh', 'relu')\n    421         if self.activation not in supported_activations:\n    422             raise ValueError(\"The activation '%s' is not supported. Supported \"\n    423                              \"activations are %s.\" % (self.activation,\n--> 424                                                       supported_activations))\n        supported_activations = ('identity', 'logistic', 'tanh', 'relu')\n    425         if self.learning_rate not in [\"constant\", \"invscaling\", \"adaptive\"]:\n    426             raise ValueError(\"learning rate %s is not supported. \" %\n    427                              self.learning_rate)\n    428         supported_solvers = _STOCHASTIC_SOLVERS + [\"lbfgs\"]\n\nValueError: The activation 'l' is not supported. Supported activations are ('identity', 'logistic', 'tanh', 'relu').\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/eolus/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\", line 973, in fit\n    hasattr(self, \"classes_\")))\n  File \"/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\", line 326, in _fit\n    self._validate_hyperparameters()\n  File \"/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\", line 424, in _validate_hyperparameters\n    supported_activations))\nValueError: The activation 'l' is not supported. Supported activations are ('identity', 'logistic', 'tanh', 'relu').\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Nov 15 17:43:54 2017\nPID: 3244                                    Python 3.6.3: /usr/bin/python3\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], {'score': <function _passthrough_scorer>}, array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), 0, {'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], {'score': <function _passthrough_scorer>}, array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), 0, {'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], y=[1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], scorer={'score': <function _passthrough_scorer>}, train=array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), verbose=0, parameters={'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1, verbose=False,\n       warm_start=False)>\n        X_train = [(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...]\n        y_train = [0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...]\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...], y=[0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...])\n    968         Returns\n    969         -------\n    970         self : returns a trained MLP model.\n    971         \"\"\"\n    972         return self._fit(X, y, incremental=(self.warm_start and\n--> 973                                             hasattr(self, \"classes_\")))\n        self = MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False)\n    974 \n    975     @property\n    976     def partial_fit(self):\n    977         \"\"\"Fit the model to data matrix X and target y.\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...], y=[0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...], incremental=False)\n    321         if not hasattr(hidden_layer_sizes, \"__iter__\"):\n    322             hidden_layer_sizes = [hidden_layer_sizes]\n    323         hidden_layer_sizes = list(hidden_layer_sizes)\n    324 \n    325         # Validate input parameters.\n--> 326         self._validate_hyperparameters()\n        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1, verbose=False,\n       warm_start=False)>\n    327         if np.any(np.array(hidden_layer_sizes) <= 0):\n    328             raise ValueError(\"hidden_layer_sizes must be > 0, got %s.\" %\n    329                              hidden_layer_sizes)\n    330 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False))\n    419         # raise ValueError if not registered\n    420         supported_activations = ('identity', 'logistic', 'tanh', 'relu')\n    421         if self.activation not in supported_activations:\n    422             raise ValueError(\"The activation '%s' is not supported. Supported \"\n    423                              \"activations are %s.\" % (self.activation,\n--> 424                                                       supported_activations))\n        supported_activations = ('identity', 'logistic', 'tanh', 'relu')\n    425         if self.learning_rate not in [\"constant\", \"invscaling\", \"adaptive\"]:\n    426             raise ValueError(\"learning rate %s is not supported. \" %\n    427                              self.learning_rate)\n    428         supported_solvers = _STOCHASTIC_SOLVERS + [\"lbfgs\"]\n\nValueError: The activation 'l' is not supported. Supported activations are ('identity', 'logistic', 'tanh', 'relu').\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Nov 15 17:43:54 2017\nPID: 3244                                    Python 3.6.3: /usr/bin/python3\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], {'score': <function _passthrough_scorer>}, array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), 0, {'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], {'score': <function _passthrough_scorer>}, array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), 0, {'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], y=[1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], scorer={'score': <function _passthrough_scorer>}, train=array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), verbose=0, parameters={'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1, verbose=False,\n       warm_start=False)>\n        X_train = [(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...]\n        y_train = [0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...]\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...], y=[0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...])\n    968         Returns\n    969         -------\n    970         self : returns a trained MLP model.\n    971         \"\"\"\n    972         return self._fit(X, y, incremental=(self.warm_start and\n--> 973                                             hasattr(self, \"classes_\")))\n        self = MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False)\n    974 \n    975     @property\n    976     def partial_fit(self):\n    977         \"\"\"Fit the model to data matrix X and target y.\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...], y=[0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...], incremental=False)\n    321         if not hasattr(hidden_layer_sizes, \"__iter__\"):\n    322             hidden_layer_sizes = [hidden_layer_sizes]\n    323         hidden_layer_sizes = list(hidden_layer_sizes)\n    324 \n    325         # Validate input parameters.\n--> 326         self._validate_hyperparameters()\n        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1, verbose=False,\n       warm_start=False)>\n    327         if np.any(np.array(hidden_layer_sizes) <= 0):\n    328             raise ValueError(\"hidden_layer_sizes must be > 0, got %s.\" %\n    329                              hidden_layer_sizes)\n    330 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False))\n    419         # raise ValueError if not registered\n    420         supported_activations = ('identity', 'logistic', 'tanh', 'relu')\n    421         if self.activation not in supported_activations:\n    422             raise ValueError(\"The activation '%s' is not supported. Supported \"\n    423                              \"activations are %s.\" % (self.activation,\n--> 424                                                       supported_activations))\n        supported_activations = ('identity', 'logistic', 'tanh', 'relu')\n    425         if self.learning_rate not in [\"constant\", \"invscaling\", \"adaptive\"]:\n    426             raise ValueError(\"learning rate %s is not supported. \" %\n    427                              self.learning_rate)\n    428         supported_solvers = _STOCHASTIC_SOLVERS + [\"lbfgs\"]\n\nValueError: The activation 'l' is not supported. Supported activations are ('identity', 'logistic', 'tanh', 'relu').\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-ea3459cd092d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best params:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best score :\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eolus/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...lib/python3/dist-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7fa5ffc9f1e0, file \"/...on3/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/lib/python3/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/lib/python3/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...lib/python3/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/lib/python3/dist-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...lib/python3/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fa5ffc9f1e0, file \"/...on3/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/lib/python3/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/lib/python3/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...lib/python3/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/lib/python3/dist-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/lib/python3/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/lib/python3/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/lib/python3/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/usr/lib/python3/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/lib/python3/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/lib/python3/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 15, 16, 43, 40, 754275, tzinfo=tzutc()), 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'session': '67FAEBD4E8A94C628B76709A783A108B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'67FAEBD4E8A94C628B76709A783A108B']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 15, 16, 43, 40, 754275, tzinfo=tzutc()), 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'session': '67FAEBD4E8A94C628B76709A783A108B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'67FAEBD4E8A94C628B76709A783A108B'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 15, 16, 43, 40, 754275, tzinfo=tzutc()), 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'session': '67FAEBD4E8A94C628B76709A783A108B', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A93AAD5E57DD4A1E97FC8C33FB4C673B', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/lib/python3/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-54-ea3459cd092d>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7fa5c0398470, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fa5a1eff5d0, file \"<ipython-input-54-ea3459cd092d>\", line 16>\n        result = <ExecutionResult object at 7fa5c0398470, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fa5a1eff5d0, file \"<ipython-input-54-ea3459cd092d>\", line 16>, result=<ExecutionResult object at 7fa5c0398470, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fa5a1eff5d0, file \"<ipython-input-54-ea3459cd092d>\", line 16>\n        self.user_global_ns = {'In': ['', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', \"get_ipython().magic('run utils/preparation.ipynb')\", \"get_ipython().magic('run utils/exploration.ipynb')\", \"get_ipython().magic('run utils/MLP_utils.ipynb')\", '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', 'errno.ENOENT', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', 'def parity_fct(attr_values):\\n    return (attr_va...pend(new_record)\\n    return pd.DataFrame(records)', 'dataset_parity_fct = generate_dataset(generate_record, 1000)\\ndataset_parity_fct.head()', '# Input data, labels\\nX, y = get_nn_inputs(dataset_parity_fct)\\n\\nprint(X[:10])\\nprint()\\nprint(y[:10])', '# Input data, labels\\nX, y = get_nn_inputs(datase...  print(r)\\nprint(\"\\\\nSample labels\")\\nprint(y[:10])', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'layer_sizes_space = [ tuple([i]) for i in range(..._rate\" : [\\'constant\\', \\'invscaling\\', \\'adaptive\\']\\n}', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'layer_sizes_space = [ tuple([i]) for i in range(..._rate\" : [\\'constant\\', \\'invscaling\\', \\'adaptive\\']\\n}', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', ...], 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {12:    Class  age  breast  breast_quad  deg_malig  i...       2           7  \n4          2           6  , 20: {'hidden_layer_sizes': [(2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), ...], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, 23: <generator object random_layer_size>, 24: <generator object random_layer_size>, 42: {'hidden_layer_sizes': [(9,)], 'learning_rate': ['constant', 'invscaling', 'adaptive']}}, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'X': [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], '_': {'hidden_layer_sizes': [(9,)], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, '_12':    Class  age  breast  breast_quad  deg_malig  i...       2           7  \n4          2           6  , '_20': {'hidden_layer_sizes': [(2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), ...], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, '_23': <generator object random_layer_size>, '_24': <generator object random_layer_size>, ...}\n        self.user_ns = {'In': ['', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', \"get_ipython().magic('run utils/preparation.ipynb')\", \"get_ipython().magic('run utils/exploration.ipynb')\", \"get_ipython().magic('run utils/MLP_utils.ipynb')\", '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', 'errno.ENOENT', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', '# Load encoded attribute values from the Breast ...l_breast_dataset_encoded.items():\\n    print(k, v)', 'def parity_fct(attr_values):\\n    return (attr_va...pend(new_record)\\n    return pd.DataFrame(records)', 'dataset_parity_fct = generate_dataset(generate_record, 1000)\\ndataset_parity_fct.head()', '# Input data, labels\\nX, y = get_nn_inputs(dataset_parity_fct)\\n\\nprint(X[:10])\\nprint()\\nprint(y[:10])', '# Input data, labels\\nX, y = get_nn_inputs(datase...  print(r)\\nprint(\"\\\\nSample labels\")\\nprint(y[:10])', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'layer_sizes_space = [ tuple([i]) for i in range(..._rate\" : [\\'constant\\', \\'invscaling\\', \\'adaptive\\']\\n}', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', 'layer_sizes_space = [ tuple([i]) for i in range(..._rate\" : [\\'constant\\', \\'invscaling\\', \\'adaptive\\']\\n}', r'from sklearn.neural_network import MLPClassifier...t score :\\n{}\".format(random_search.best_score_))', ...], 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'Out': {12:    Class  age  breast  breast_quad  deg_malig  i...       2           7  \n4          2           6  , 20: {'hidden_layer_sizes': [(2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), ...], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, 23: <generator object random_layer_size>, 24: <generator object random_layer_size>, 42: {'hidden_layer_sizes': [(9,)], 'learning_rate': ['constant', 'invscaling', 'adaptive']}}, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'X': [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], '_': {'hidden_layer_sizes': [(9,)], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, '_12':    Class  age  breast  breast_quad  deg_malig  i...       2           7  \n4          2           6  , '_20': {'hidden_layer_sizes': [(2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), ...], 'learning_rate': ['constant', 'invscaling', 'adaptive']}, '_23': <generator object random_layer_size>, '_24': <generator object random_layer_size>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/home/eolus/Desktop/DAUPHINE/data_mining/DM/DM2/MultiLayerPerceptron_exercise/<ipython-input-54-ea3459cd092d> in <module>()\n     11     cv=10, # 10-fold cross-validation\n     12     verbose=0,\n     13     random_state=None\n     14 )\n     15 \n---> 16 random_search.fit(X, y)\n     17 print(\"best params:\\n{}\".format(random_search.best_params_))\n     18 print(\"best score :\\n{}\".format(random_search.best_score_))\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=RandomizedSearchCV(cv=10, error_score='raise',\n ...turn_train_score='warn', scoring=None, verbose=0), X=[(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], y=[1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...d(n_splits=10, random_state=None, shuffle=False)>\n        X = [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...]\n        y = [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=4), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=4)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Nov 15 17:43:54 2017\nPID: 3244                                    Python 3.6.3: /usr/bin/python3\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], {'score': <function _passthrough_scorer>}, array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), 0, {'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), [(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], {'score': <function _passthrough_scorer>}, array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), 0, {'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(4, 1, 2, 1, 0, 1, 1, 2, 10), (3, 1, 2, 0, 0, 1, 1, 0, 5), (2, 0, 4, 0, 3, 0, 2, 0, 1), (4, 0, 0, 0, 4, 1, 2, 2, 7), (5, 0, 1, 1, 4, 0, 1, 2, 6), (0, 1, 1, 2, 6, 1, 1, 0, 8), (1, 1, 3, 0, 4, 1, 2, 1, 4), (5, 1, 3, 1, 5, 0, 2, 2, 10), (5, 0, 2, 2, 2, 1, 1, 2, 4), (0, 0, 1, 1, 3, 0, 1, 2, 8), (0, 0, 5, 1, 6, 0, 0, 2, 4), (2, 1, 5, 1, 5, 1, 2, 1, 1), (2, 1, 2, 1, 1, 1, 2, 1, 2), (2, 1, 1, 2, 3, 1, 0, 1, 2), (2, 1, 3, 1, 6, 1, 2, 2, 1), (2, 1, 0, 1, 0, 0, 0, 0, 1), (5, 0, 5, 2, 3, 1, 0, 1, 8), (3, 1, 2, 1, 1, 0, 2, 1, 0), (4, 1, 5, 2, 6, 1, 2, 1, 9), (2, 1, 1, 0, 4, 1, 2, 2, 9), ...], y=[1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, ...], scorer={'score': <function _passthrough_scorer>}, train=array([ 98, 102, 103, 104, 105, 106, 107, 108, 1..., 992, 993, 994, 995, 996, 997,\n       998, 999]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...91,  92,  93,  94,  95,  96,  97,  99, 100, 101]), verbose=0, parameters={'activation': 'l', 'alpha': 0.0009797959183673469, 'hidden_layer_sizes': (10, 7, 15, 10, 6, 3, 6, 15, 10, 4, 2, 7, 13, 9), 'learning_rate': 'adaptive', 'learning_rate_init': 0.002726530612244898, 'momentum': 0.59999999999999998, 'solver': 'lbfgs'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1, verbose=False,\n       warm_start=False)>\n        X_train = [(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...]\n        y_train = [0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...]\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...], y=[0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...])\n    968         Returns\n    969         -------\n    970         self : returns a trained MLP model.\n    971         \"\"\"\n    972         return self._fit(X, y, incremental=(self.warm_start and\n--> 973                                             hasattr(self, \"classes_\")))\n        self = MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False)\n    974 \n    975     @property\n    976     def partial_fit(self):\n    977         \"\"\"Fit the model to data matrix X and target y.\n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False), X=[(1, 1, 2, 1, 4, 1, 0, 1, 7), (2, 1, 0, 0, 6, 1, 0, 2, 5), (2, 1, 3, 1, 0, 0, 0, 1, 0), (0, 0, 2, 0, 0, 0, 0, 0, 8), (3, 1, 5, 0, 3, 0, 1, 2, 1), (4, 1, 1, 1, 2, 1, 1, 1, 0), (1, 0, 1, 2, 6, 0, 1, 0, 6), (2, 1, 4, 1, 4, 1, 1, 1, 6), (4, 0, 5, 1, 6, 0, 1, 2, 5), (5, 0, 4, 0, 2, 0, 2, 0, 0), (4, 1, 4, 0, 0, 0, 2, 1, 10), (1, 0, 4, 1, 3, 1, 2, 2, 8), (3, 0, 2, 1, 6, 1, 0, 2, 0), (0, 1, 4, 1, 2, 1, 2, 2, 9), (4, 0, 2, 2, 6, 1, 2, 1, 10), (5, 1, 5, 1, 4, 0, 0, 2, 10), (4, 0, 2, 0, 4, 1, 2, 2, 3), (0, 0, 5, 2, 6, 0, 0, 0, 1), (2, 1, 1, 2, 5, 1, 1, 2, 4), (2, 1, 2, 2, 5, 0, 2, 0, 9), ...], y=[0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, ...], incremental=False)\n    321         if not hasattr(hidden_layer_sizes, \"__iter__\"):\n    322             hidden_layer_sizes = [hidden_layer_sizes]\n    323         hidden_layer_sizes = list(hidden_layer_sizes)\n    324 \n    325         # Validate input parameters.\n--> 326         self._validate_hyperparameters()\n        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1, verbose=False,\n       warm_start=False)>\n    327         if np.any(np.array(hidden_layer_sizes) <= 0):\n    328             raise ValueError(\"hidden_layer_sizes must be > 0, got %s.\" %\n    329                              hidden_layer_sizes)\n    330 \n\n...........................................................................\n/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='l', alpha=0.0009797959...tion=0.1, verbose=False,\n       warm_start=False))\n    419         # raise ValueError if not registered\n    420         supported_activations = ('identity', 'logistic', 'tanh', 'relu')\n    421         if self.activation not in supported_activations:\n    422             raise ValueError(\"The activation '%s' is not supported. Supported \"\n    423                              \"activations are %s.\" % (self.activation,\n--> 424                                                       supported_activations))\n        supported_activations = ('identity', 'logistic', 'tanh', 'relu')\n    425         if self.learning_rate not in [\"constant\", \"invscaling\", \"adaptive\"]:\n    426             raise ValueError(\"learning rate %s is not supported. \" %\n    427                              self.learning_rate)\n    428         supported_solvers = _STOCHASTIC_SOLVERS + [\"lbfgs\"]\n\nValueError: The activation 'l' is not supported. Supported activations are ('identity', 'logistic', 'tanh', 'relu').\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='sgd', max_iter=800) # default parameters\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    clf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100, # 30 (random) search iteration\n",
    "    n_jobs=4, # 4 parallel jobs\n",
    "    refit=True,\n",
    "    cv=10, # 10-fold cross-validation\n",
    "    verbose=0,\n",
    "    random_state=None\n",
    ")\n",
    "\n",
    "random_search.fit(X, y)\n",
    "print(\"best params:\\n{}\".format(random_search.best_params_))\n",
    "print(\"best score :\\n{}\".format(random_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
