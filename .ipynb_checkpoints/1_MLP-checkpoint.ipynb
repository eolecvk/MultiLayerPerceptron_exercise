{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run utils/helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run utils/MLP_utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample records:\n",
      "(2, 2, 2, 0, 2, 2, 1, 3, 0)\n",
      "(3, 0, 2, 0, 1, 0, 1, 1, 0)\n",
      "(2, 2, 6, 0, 2, 2, 1, 2, 1)\n",
      "(2, 2, 5, 4, 2, 1, 0, 5, 0)\n",
      "(3, 2, 4, 4, 1, 1, 1, 3, 1)\n",
      "(3, 0, 7, 0, 1, 2, 0, 3, 0)\n",
      "(2, 2, 1, 0, 1, 1, 0, 3, 0)\n",
      "(2, 2, 0, 0, 1, 1, 1, 4, 0)\n",
      "(2, 0, 7, 2, 2, 1, 1, 3, 1)\n",
      "(3, 2, 4, 0, 1, 1, 0, 2, 0)\n",
      "...\n",
      "\n",
      "Sample labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "fpath = '/tmp/training.pkl'\n",
    "X, y = load_pickle(fpath)\n",
    "\n",
    "# Preview\n",
    "print(\"Sample records:\")\n",
    "for r in X[:10]:\n",
    "    print(r)\n",
    "print(\"...\")\n",
    "print(\"\\nSample labels\")\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "steps = [\n",
    "    ('scaler', StandardScaler()), # data scaling\n",
    "    ('clf', MLPClassifier()) # Multilayer Perceptron\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "max_layers = 5\n",
    "max_neurons = 20\n",
    "layer_space_list = []\n",
    "for i in range(1, max_layers+1):\n",
    "    i_layers = list(product(list(range(1, max_neurons+1)), repeat=i))\n",
    "    layer_space_list.extend(i_layers) # all config: i layers\n",
    "layer_space = tuple(layer_space_list)\n",
    "\n",
    "param_grid = {\n",
    "    'clf__hidden_layer_sizes' : layer_space, # (100,)\n",
    "    'clf__max_iter' : (800, 1000, 1200),\n",
    "    'clf__activation' : ['identity', 'logistic', 'tanh', 'relu'], # 'relu'\n",
    "    'clf__solver' : ['lbfgs', 'sgd', 'adam'], #'adam'\n",
    "    'clf__alpha' : np.linspace(start=0.00001, stop=0.001, num=50), #0.0001\n",
    "    'clf__learning_rate' : ['constant', 'invscaling', 'adaptive'], #'constant'\n",
    "    'clf__learning_rate_init' : np.linspace(start=0.0001, stop=0.01, num=50), #0.001\n",
    "    'clf__momentum' : np.linspace(start=0.1, stop=1, num=10) #0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization (random), with KFold (K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (800) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/eolus/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (600) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rat...=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False))]),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=8,\n",
       "          param_distributions={'clf__hidden_layer_sizes': ((1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,), (10,), (11,), (12,), (13,), (14,), (15,), (16,), (17,), (18,), (19,), (20,), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1,... ,  0.01   ]), 'clf__momentum': array([ 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100, # search-iterations\n",
    "    n_jobs=8, # parallel jobs\n",
    "    refit=True,\n",
    "    cv=10, # 10-fold cross-validation\n",
    "    verbose=0,\n",
    "    random_state=None\n",
    ")\n",
    "\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# .../.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564:\n",
    "# ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
    "#   % self.max_iter, ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params [score=0.7508771929824561]:\n",
      "{\n",
      "  \"activation\": \"tanh\",\n",
      "  \"alpha\": 7.061224489795919e-05,\n",
      "  \"hidden_layer_sizes\": [\n",
      "    20,\n",
      "    20,\n",
      "    5,\n",
      "    16,\n",
      "    12\n",
      "  ],\n",
      "  \"learning_rate\": \"constant\",\n",
      "  \"learning_rate_init\": 0.008181632653061224,\n",
      "  \"max_iter\": 800,\n",
      "  \"momentum\": 1.0,\n",
      "  \"solver\": \"sgd\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "best_params_pipeline = random_search.best_params_\n",
    "best_score_pipeline = random_search.best_score_\n",
    "\n",
    "clf_args = {\n",
    "    'activation' : best_params_pipeline['clf__activation'],\n",
    "    'alpha' : best_params_pipeline['clf__alpha'],\n",
    "    'hidden_layer_sizes' : best_params_pipeline['clf__hidden_layer_sizes'],\n",
    "    'learning_rate' : best_params_pipeline['clf__learning_rate'],\n",
    "    'learning_rate_init' : best_params_pipeline['clf__learning_rate_init'],\n",
    "    'max_iter' : best_params_pipeline['clf__max_iter'],\n",
    "    'max_iter' : best_params_pipeline['clf__max_iter'],\n",
    "    'momentum' : best_params_pipeline['clf__momentum'],\n",
    "    'solver' : best_params_pipeline['clf__solver']\n",
    "}\n",
    "\n",
    "\n",
    "save_json(clf_args, '/tmp/clf_args_cancer.json')\n",
    "print(\"best params [score={}]:\".format(best_score_pipeline))\n",
    "pprint(clf_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
