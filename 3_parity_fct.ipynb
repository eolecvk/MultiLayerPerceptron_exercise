{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization of XOR: parity function problem\n",
    "\n",
    "Generalize the previous analysis with functions taking 3 to 10 input variables.  \n",
    "We shall use a dataset to train on the parity function problem:\n",
    "fonction returns 1 when there is an even number of 1-valued attributes; else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run utils/helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run utils/preparation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run utils/exploration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run utils/MLP_utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load attribute dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age [2, 3, 4, 1, 5, 0]\n",
      "menopause [2, 0, 1]\n",
      "tumor_size [2, 6, 5, 4, 7, 1, 0, 3, 8, 10, 9]\n",
      "inv_nodes [0, 4, 2, 5, 6, 3, 1]\n",
      "node_caps [2, 1, 0]\n",
      "deg_malig [2, 0, 1]\n",
      "breast [1, 0]\n",
      "breast_quad [3, 1, 2, 5, 4, 0]\n",
      "irradiat [0, 1]\n",
      "Class [1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Load encoded attribute values from the Breast Cancer dataset\n",
    "fpath = \"/tmp/DM2_attr_val_encoded.json\"\n",
    "attr_val_breast_dataset_encoded = load_json(fpath)\n",
    "    \n",
    "# Preview\n",
    "for k, v in attr_val_breast_dataset_encoded.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then generate sample records randomly and classify them using the parity function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MLP model training pipeline for XOR datasets (3 to 10 features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Dataset size: 800\n",
      "Sample records:\n",
      "(1, 1, 0)\n",
      "(0, 1, 1)\n",
      "(0, 2, 0)\n",
      "(1, 1, 1)\n",
      "(1, 0, 1)\n",
      "(1, 1, 1)\n",
      "(1, 1, 0)\n",
      "(0, 1, 1)\n",
      "(1, 1, 0)\n",
      "(0, 0, 0)\n",
      "\n",
      "Sample labels\n",
      "[1, 1, 1, 0, 1, 0, 1, 1, 1, 1]\n",
      "best params [score=0.8875]:\n",
      "{\n",
      "  \"activation\": \"tanh\",\n",
      "  \"alpha\": 0.005514693877551021,\n",
      "  \"hidden_layer_sizes\": [\n",
      "    1,\n",
      "    2\n",
      "  ],\n",
      "  \"learning_rate\": \"constant\",\n",
      "  \"learning_rate_init\": 0.00979795918367347,\n",
      "  \"max_iter\": 1300,\n",
      "  \"momentum\": 0.8,\n",
      "  \"solver\": \"lbfgs\"\n",
      "}\n",
      "\t---------------------------\n",
      "\n",
      "4\n",
      "Dataset size: 800\n",
      "Sample records:\n",
      "(0, 1, 1, 1)\n",
      "(0, 5, 2, 0)\n",
      "(1, 1, 0, 1)\n",
      "(1, 4, 1, 1)\n",
      "(0, 1, 0, 0)\n",
      "(0, 3, 2, 1)\n",
      "(0, 1, 1, 0)\n",
      "(0, 1, 1, 1)\n",
      "(0, 3, 1, 0)\n",
      "(0, 1, 2, 0)\n",
      "\n",
      "Sample labels\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "best params [score=0.785]:\n",
      "{\n",
      "  \"activation\": \"tanh\",\n",
      "  \"alpha\": 0.009796122448979592,\n",
      "  \"hidden_layer_sizes\": [\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"learning_rate\": \"constant\",\n",
      "  \"learning_rate_init\": 0.0011102040816326532,\n",
      "  \"max_iter\": 1600,\n",
      "  \"momentum\": 0.7000000000000001,\n",
      "  \"solver\": \"lbfgs\"\n",
      "}\n",
      "\t---------------------------\n",
      "\n",
      "5\n",
      "Dataset size: 800\n",
      "Sample records:\n",
      "(1, 0, 0, 1, 9)\n",
      "(1, 1, 1, 0, 2)\n",
      "(0, 1, 1, 0, 10)\n",
      "(3, 0, 1, 1, 2)\n",
      "(1, 0, 1, 1, 2)\n",
      "(1, 1, 1, 1, 1)\n",
      "(4, 0, 2, 1, 10)\n",
      "(1, 1, 1, 1, 1)\n",
      "(2, 1, 2, 2, 1)\n",
      "(0, 0, 2, 1, 2)\n",
      "\n",
      "Sample labels\n",
      "[1, 0, 1, 1, 0, 0, 0, 0, 1, 0]\n",
      "best params [score=0.65875]:\n",
      "{\n",
      "  \"activation\": \"tanh\",\n",
      "  \"alpha\": 0.0016410204081632655,\n",
      "  \"hidden_layer_sizes\": [\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"learning_rate\": \"constant\",\n",
      "  \"learning_rate_init\": 0.003938775510204082,\n",
      "  \"max_iter\": 1300,\n",
      "  \"momentum\": 0.9,\n",
      "  \"solver\": \"adam\"\n",
      "}\n",
      "\t---------------------------\n",
      "\n",
      "6\n",
      "Dataset size: 800\n",
      "Sample records:\n",
      "(4, 2, 6, 0, 0, 5)\n",
      "(4, 2, 4, 0, 0, 5)\n",
      "(1, 0, 1, 1, 1, 4)\n",
      "(1, 1, 3, 0, 2, 5)\n",
      "(2, 2, 3, 1, 0, 7)\n",
      "(2, 2, 0, 0, 0, 10)\n",
      "(1, 2, 1, 1, 1, 1)\n",
      "(3, 1, 1, 1, 1, 1)\n",
      "(1, 2, 6, 0, 2, 2)\n",
      "(3, 1, 3, 0, 0, 1)\n",
      "\n",
      "Sample labels\n",
      "[1, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "best params [score=0.61375]:\n",
      "{\n",
      "  \"activation\": \"tanh\",\n",
      "  \"alpha\": 0.009796122448979592,\n",
      "  \"hidden_layer_sizes\": [\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"learning_rate\": \"constant\",\n",
      "  \"learning_rate_init\": 0.002726530612244898,\n",
      "  \"max_iter\": 1600,\n",
      "  \"momentum\": 0.4,\n",
      "  \"solver\": \"lbfgs\"\n",
      "}\n",
      "\t---------------------------\n",
      "\n",
      "7\n",
      "Dataset size: 800\n",
      "Sample records:\n",
      "(1, 1, 1, 1, 0, 0, 1)\n",
      "(3, 1, 0, 4, 1, 1, 1)\n",
      "(4, 1, 0, 1, 1, 2, 1)\n",
      "(5, 0, 0, 3, 0, 0, 8)\n",
      "(1, 1, 1, 1, 1, 1, 1)\n",
      "(4, 4, 2, 4, 0, 0, 1)\n",
      "(5, 1, 0, 4, 0, 2, 2)\n",
      "(4, 2, 2, 2, 0, 2, 5)\n",
      "(1, 1, 1, 1, 1, 1, 1)\n",
      "(1, 2, 1, 1, 0, 1, 1)\n",
      "\n",
      "Sample labels\n",
      "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0]\n",
      "best params [score=0.62875]:\n",
      "{\n",
      "  \"activation\": \"tanh\",\n",
      "  \"alpha\": 0.005514693877551021,\n",
      "  \"hidden_layer_sizes\": [\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"learning_rate\": \"adaptive\",\n",
      "  \"learning_rate_init\": 0.003130612244897959,\n",
      "  \"max_iter\": 1600,\n",
      "  \"momentum\": 0.4,\n",
      "  \"solver\": \"lbfgs\"\n",
      "}\n",
      "\t---------------------------\n",
      "\n",
      "8\n",
      "Dataset size: 800\n",
      "Sample records:\n",
      "(3, 0, 0, 4, 1, 2, 1, 2)\n",
      "(1, 1, 1, 1, 1, 1, 1, 8)\n",
      "(0, 0, 3, 1, 0, 2, 2, 2)\n",
      "(2, 1, 5, 1, 1, 1, 1, 1)\n",
      "(4, 0, 4, 3, 0, 2, 0, 8)\n",
      "(1, 1, 3, 4, 0, 0, 1, 2)\n",
      "(2, 0, 3, 1, 0, 0, 2, 10)\n",
      "(0, 0, 5, 4, 0, 0, 2, 0)\n",
      "(1, 1, 3, 1, 1, 1, 1, 1)\n",
      "(5, 1, 1, 0, 0, 1, 2, 6)\n",
      "\n",
      "Sample labels\n",
      "[1, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n",
      "best params [score=0.595]:\n",
      "{\n",
      "  \"activation\": \"tanh\",\n",
      "  \"alpha\": 0.005922448979591837,\n",
      "  \"hidden_layer_sizes\": [\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"learning_rate\": \"invscaling\",\n",
      "  \"learning_rate_init\": 0.008585714285714287,\n",
      "  \"max_iter\": 1600,\n",
      "  \"momentum\": 0.7000000000000001,\n",
      "  \"solver\": \"lbfgs\"\n",
      "}\n",
      "\t---------------------------\n",
      "\n",
      "9\n",
      "Dataset size: 800\n",
      "Sample records:\n",
      "(1, 0, 2, 0, 1, 0, 2, 1, 6)\n",
      "(5, 0, 2, 0, 2, 0, 1, 2, 2)\n",
      "(1, 0, 3, 0, 1, 1, 1, 1, 4)\n",
      "(3, 0, 0, 2, 0, 0, 0, 0, 1)\n",
      "(4, 0, 5, 0, 6, 0, 2, 2, 2)\n",
      "(4, 0, 5, 0, 2, 0, 0, 2, 4)\n",
      "(1, 1, 1, 1, 1, 1, 1, 1, 1)\n",
      "(1, 1, 1, 1, 3, 1, 1, 1, 5)\n",
      "(0, 0, 0, 0, 1, 0, 2, 0, 4)\n",
      "(0, 1, 1, 0, 1, 0, 1, 2, 0)\n",
      "\n",
      "Sample labels\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 0, 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-56397c8cc862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpprint_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_neurons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpprint_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-77d682523208>\u001b[0m in \u001b[0;36mfind_best_model\u001b[0;34m(X, y, n_iter, max_layers, max_neurons)\u001b[0m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eolus/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eolus/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n_attributes in range(3, 11):\n",
    "    \n",
    "    print(\"{} attributes:\".format(n_attributes))\n",
    "    \n",
    "    #print(\"Training for {n_attributes}-attributes XOR dataset:\".format(n_attributes))\n",
    "    \n",
    "    XOR_df = generate_XOR_dataset(n_examples=800,\n",
    "                         attr_dict=attr_val_breast_dataset_encoded,\n",
    "                         n_attributes=n_attributes,\n",
    "                         no_duplicate=False)\n",
    "    \n",
    "    X, y = get_nn_inputs(XOR_df)\n",
    "    \n",
    "    pprint_X_y(X, y)\n",
    "    \n",
    "    best_model = find_best_model(X, y, n_iter=300, max_layers=15, max_neurons=15)\n",
    "    \n",
    "    pprint_best_model(best_model)\n",
    "    print('\\t---------------------------\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
